{
    "file_name": "server_10.15_developer_manual_testing_acceptance-tests.html",
    "file_path": "./owncloud_docs\\server_10.15_developer_manual_testing_acceptance-tests.html",
    "chunks": [
        {
            "cluster": 2,
            "chunk_content": "Documentation for ownCloud (A Kiteworks Company)\nownCloud Server\nIntroduction\nAdmin Manual\nIntroduction\nUseful Pages\nFAQ\nGDPR\nInstallation\nDeployment Considerations\nDeployment Recommendations\nNFS\nSystem Requirements\nConfiguration Notes and Tips\nInstallation Options\nInstalling With Docker\nManual Installation on Linux\nDetailed Installation Guide\nDetailed Installation on Ubuntu (various versions)\nQuick Installation Guide\nOn Ubuntu 20.04\nOn Ubuntu 22.04\nLinux Package Manager\nLinux Package Manager Installation\nThe Installation Wizard\nTroubleshooting\nChanging Your ownCloud URL\nInstalling and Managing Apps\nSupported Apps\nMedia Viewer\nSELinux Configuration\nUsing Let’s Encrypt SSL Certificates\nUsing Letsencrypt\nApache\nConfiguration\nDatabase\nDatabase Conversion\nDatabase Configuration\nEncryption\nEncryption Configuration\nEncryption Configuration Quick Guide\nExternal Storage\nExternal Storage Configuration\nExternal Storage Authentication Mechanisms\nAmazonS3\nDropbox\nFTP\nGoogle\nLocal\nownCloud\nS3 as Primary\nSFTP\nSMB\nWebDAV\nFiles and Sharing\nBig File Upload Configuration\nManual File Locking\nDefault Files Configuration\nFederated Cloud Sharing Configuration\nFile Sharing Configuration\nFile Versioning\nTransactional File Locking\nPreview Configuration\nMimetypes\nManaging the Trashbin\nIntegration\nMicrosoft Teams\nownCloud App for Splunk\nGeneral Topics\nCode Signing\nImpersonate Users\nFull Text Search\nServer\nActivity Configuration\nBackground Jobs Configuration\nCaching Configuration\nConfig Sample PHP Parameters\nConfig Apps Sample PHP Parameters\nCustom Client Repos\nEmail Configuration\nExcluded Blacklisted Files\nExternal Sites\nHarden Server\nImport SSL Cert\nIndex PHP Less URLs\nOCC Command\nLanguage Configuration\nLegal Settings Configuration\nLogging\nLogging Configuration\nRequest Tracing\nReverse Proxy Configuration\nSecurity\nBrute-Force Protection\nOAuth2\nPassword policy\nSecurity Setup Warnings\nThe HSM (Hardware Security Module) Daemon\nDependency Notes\nServer Tuning\nThird Party PHP Configuration\nVirus Scanner Support\nUI Configuration\nUser\nUser Management\nUser Roles\nReset Admin Password\nReset User Password\nUser Auth FTP SMB IMAP\nUser Auth LDAP\nUser Auth Two-Factor\nUser Auth OAuth2\nUser Provisioning API\nCustom Groups App\nGuests App\nOpenID Connect (OIDC)\nLogin Policies\nMaintenance\nUpgrading\nManual Upgrade\nDatabase Upgrade\nUpgrading from Package\nUsing the Updater App\nUpgrading PHP\nMarketplace Apps\nBackup and Restore\nBackup\nRestore\nMaintenance Mode\nExport and Import Instance Data\nManually Moving Data Folders\nEncryption\nMigrating from User Key to Master Key Encryption\nMigrating to a Different Server\nMigrating to Kiteworks PCN\nEnterprise\nAuthentication\nEnterprise Only Authentication\nKerberos Authentication\nClients\nCustom Client Repos\nCollaboration\nCollabora Online / Secure View\nMicrosoft Office Online / WOPI Integration\nDocument Classification\nClassify Documents and Enforce Policies\nExternal Storage\nLDAP Home Connector Configuration\nSharepoint integration Configuration\nWindows Network Drive Configuration\nWND Configuration Quick Guide\nFile Management\nFile Tagging\nFile Lifecycle Management\nFirewall\nFile Firewall\nInstallation\nInstalling & Upgrading ownCloud Enterprise Edition\nOracle DB Setup & Configuration\nLogging\nAuditing\nReporting\nMetrics\nGenerate a Config Report\nSecurity\nRansomware Protection\nUser Management\nShibboleth Integration\nSAML 2.0 Based SSO\nTroubleshooting\nGeneral Troubleshooting\nPath and Filename Length Limitations\nRetrieve Log Files and Configuration Settings\nRemove Non-Existent Background Jobs\nFound a Mistake? ownCloud Server UI\nIntroduction\nThe WebUI\nWeb Interface\nNavigating the WebUI\nPersonal Settings\nGeneral\nStorage\nSharing\nSecurity\nCustom Groups\nFiles\nAccess WebDAV\nSharing Files\nSearch & Full Text Search\nTagging Files\nComments\nVersion Control\nEncrypting Files\nManaging Deleted Files\nLarge File Uploads\nManual File Locking\nFile Lifecycle Management\nPublic Link Shares\nFederated Cloud Sharing\nManaging Connected Browsers and Devices\nOnline Collaboration\nStorage Quotas\nExternal Storage\nConnecting to SharePoint\nDesktop Mobile Sync\nApps\nActivity\nCalendar\nContacts\nMarket\nMedia Viewer App\nIntegration\nMicrosoft Teams\nSynchronization Clients\nSync iOS\nSync KDE\nSync OSX\nSync Thunderbird\nTroubleshooting\nFound a Mistake? filesForUpload/\nThis folder contains convenience files that tests can use to upload. For example, running\nocc\ncommands to set system and app config settings. apps/testing/data/tinySkeleton/\nThis folder stores just a single file. This is useful when wanting to test with a skeleton and there is no need for more than one file. apps/testing/data/smallSkeleton/\nThis folder stores a small set of initial files to be loaded for a new user. apps/testing/data/largeSkeleton/\nThis folder stores a larger set of initial files to be loaded for a new user. These can be convenient when a longer list of files is needed, e.g., in a UI test that scrolls a file list. After cloning core, run\nmake\nas your webserver’s user in the root directory of the project. Edit that file\nand specify the values to be used at run time. In the\nacceptance\nsection of\n.drone.star\nswitch on the\nreplaceUsernames\nsetting. This functionality is most useful in CI. The following two methods can be used to achieve this:\n1. Scenario: sharee comments on a group shared file\nGiven group \"grp1\" has been created\n[Paused after \"group \"grp1\" has been created\" - press enter to continue]\nAnd user \"Brian\" has been added to group \"grp1\"\n[Paused after \"user \"Brian\" has been added to group \"grp1\"\" - press enter to continue]\nAnd user \"Alice\" has uploaded file \"filesForUpload/textfile.txt\" to \"/myFileToComment.txt\"\n[Paused after \"user \"Alice\" has uploaded file \"filesForUpload/textfile.txt\" to \"/myFileToComment.txt\"\" - press enter to continue]\n...\nGet Detailed Information About API Requests\nIf you set any of these environment variables, then the test runner will display information about the details of each request to and response from the API. Feature Files\nEach feature file describes and tests a particular feature of the software. The feature file starts with the\nFeature:\nkeyword, a sentence describing the feature. This is followed by more detail explaining who uses the feature and why, in the format:\nAs a [role]\nI want [feature]\nSo that [benefit]\nFor example:\nFeature: upload file using the WebDav API\nAs a user\nI want to be able to upload files\nSo that I can store and share files between multiple client systems\nThis detail is free-text and has no effect on the running of automated tests. Make small feature files for individual features. For example \"the Provisioning API\" is too big to be a single feature. Split it into the functional things that it allows a client to do. For example:\naddGroup.feature\naddUser.feature\naddToGroup.feature\ndeleteGroup.feature\ndeleteUser.feature\ndisableUser.feature\neditUser.feature\nenableUser.feature\nremoveFromGroup.feature\nTest Scenarios\nA feature file should have up to 10 or 20 scenarios that test the feature. For example:\nScenario: delete files in a sub-folder\nGiven user \"Alice\" has been created\nAnd user \"Alice\" has moved file \"/welcome.txt\" to \"/FOLDER/welcome.txt\"\nAnd user \"Alice\" has created a folder \"/FOLDER/SUBFOLDER\"\nAnd user \"Alice\" has copied file \"/textfile0.txt\" to \"/FOLDER/SUBFOLDER/testfile0.txt\"\nGiven\nsteps do not mention how the action is done. For example, creating a user must be done by something with enough admin privilege. So there is no need to mention \"the administrator\". But creating a file must be done in the context of some user. So the user must be mentioned. Continuing the example above:\nScenario: delete all files in a sub-folder\nGiven user \"Alice\" has been created\nAnd user \"Alice\" has moved file \"/welcome.txt\" to \"/FOLDER/welcome.txt\"\nAnd user \"Alice\" has created a folder \"/FOLDER/SUBFOLDER\"\nAnd user \"Alice\" has copied file \"/textfile0.txt\" to \"/FOLDER/SUBFOLDER/testfile0.txt\"\nWhen user \"Alice\" deletes everything from folder \"/FOLDER/\" using the WebDAV API\nIn ownCloud there are usually 2 or 3 interfaces that can implement an action. For example, a user can be created using an\nocc\ncommand, the Provisioning API or the webUI. Files can be managed using the WebDAV API or the webUI. File shares can be managed using the Sharing API or the webUI. For example, when the\nuser moves or copies a file they go through a few actions. But sometimes there\nare points in the workflow where the user has the option to take a different path. Scenario: cancel copying a file\nGiven user \"Alice\" has logged in using the webUI\nAnd the user has browsed to the files page\nWhen the user opens the file action menu of folder \"data.zip\" using the webUI\nAnd the user selects the copy action for folder \"data.zip\" using the webUI\nAnd the user selects the folder \"simple-empty-folder\" as a place to copy the file using the webUI\nAnd the user cancels the attempt to copy the file into folder \"simple-empty-folder\" using the webUI\nThen file \"data.zip\" should be listed on the webUI\nBut file \"data.zip\" should not be listed in the folder \"simple-empty-folder\" on the webUI\nWriting a Then Step\nThen\nsteps describe what should be the case if the\nWhen\nstep(s) happened successfully. Scenario: delete all files in a sub-folder\nGiven user \"Alice\" has been created\nAnd user \"Alice\" has moved file \"/welcome.txt\" to \"/FOLDER/welcome.txt\"\nAnd user \"Alice\" has created a folder \"/FOLDER/SUBFOLDER\"\nAnd user \"Alice\" has copied file \"/textfile0.txt\" to \"/FOLDER/SUBFOLDER/testfile0.txt\"\nWhen user \"Alice\" deletes everything from folder \"/FOLDER/\" using the WebDAV API\nThen user \"Alice\" should see the following elements\n| /FOLDER/           |\n| /PARENT/           |\n| /PARENT/parent.txt |\n| /textfile0.txt     |\n| /textfile1.txt     |\n| /textfile2.txt     |\n| /textfile3.txt     |\n| /textfile4.txt     |\nBut user \"Alice\" should not see the following elements\n| /FOLDER/SUBFOLDER/              |\n| /FOLDER/welcome.txt             |\n| /FOLDER/SUBFOLDER/testfile0.txt |\nNote that there are often multiple things that\nshould\nor\nshould not\nbe the case after the\nWhen\naction. For example, in the above scenario, various files and folders (that are part of the skeleton) should still be there. But other files and folders under\nFOLDER\nshould have been deleted. For example:\nScenario: admin creates a user\nGiven user \"brand-new-user\" has been deleted\nWhen the administrator sends a user creation request for user \"brand-new-user\" password \"%alt1%\" using the provisioning API\nThen the OCS status code should be \"100\"\nAnd the HTTP status code should be \"200\"\nAnd user \"brand-new-user\" should exist\nAnd user \"brand-new-user\" should be able to access a skeleton file\nIn this scenario we check that the OCS and HTTP status codes of the API request are good. But it is possible that the server lies, and returns HTTP status 200 for every request, even if the server did not create the user. So we check that the user exists. However maybe the user exists according to some API that can query for valid user names/ids,\nbut the user account is not really valid and working. So we also check that the user can do something, in this case that they can access one of their skeleton files. For example, the user. Use realistic user names, display names and email addresses when writing scenarios. Use those usernames unless there is some special reason not to. So you can just create these users in\nGiven\nsteps and they get the corresponding display name and email address. User Name\nDisplay Name\nEmail Address\nDescription\nAlice\nAlice Hansen\nalice@example.org\nThe primary actor in a scenario, e.g. the one doing the sharing\nBrian\nBrian Murphy\nbrian@example.org\nThe second actor, e.g., the one receiving a share\nCarol\nCarol King\ncarol@example.org\nThe third actor, e.g., might be a member of a group\nDavid\nDavid Lopez\ndavid@example.org\nAnother actor, when needed\nEmily\nEmily Wagner\nemily@example.org\nAnother actor, when needed\nThe acceptance test code can remember the \"current\" user with a step like:\nGiven as user \"Alice\"\nAnd the user has uploaded file \"abc.txt\"\nWhen the user deletes file \"abc.txt\"\n... Or you can mention the user in each step:\nGiven user \"Alice\" has uploaded file \"abc.txt\"\nWhen user \"Alice\" deletes file \"abc.txt\"\n... Do not write\nWhen user \"admin\" does something\n. The user name of the administrator needs to be determined at run-time, not hard-coded in the scenario. Referring to Named Entities\nWhen referring to specific named entities on the system, such as a user, group, file, folder or tag,\nthen do not put the word\nthe\nin front, but do put the name of the entity. For example:\nGiven user \"Alice\" has been added to group \"grp1\"\nAnd user \"Alice\" has uploaded file \"abc.txt\" into folder \"folder1\"\nAnd user \"Alice\" has added tag \"aTag\" to file \"folder1/abc.txt\"\nWhen user \"Alice\" shares folder \"folder1\" with user \"Brian\"\n... For example:\nAnd \"Alice\" has uploaded \"abc.txt\" into \"folder1\"\n...\nwould be less clear that the required entities for this step are a user, file and folder. For example:\nBackground:\nGiven user \"Alice\" has been created\nAnd user \"Brian\" has been created\nAnd user \"Alice\" has uploaded file \"abc.txt\"\nScenario: share a file with another user\nWhen user \"Alice\" shares file \"abc.txt\" with user \"Brian\" using the sharing API\nThen the HTTP status code should be \"200\"\nAnd user \"Brian\" should be able to download file \"abc.txt\"\nScenario: share a file with a group\nGiven group \"grp1\" has been created\nAnd \"Brian\" has been added to group \"grp1\"\nWhen user \"Alice\" shares file \"abc.txt\" with user \"Brian\" using the sharing API\nThen the HTTP status code should be \"200\"\nAnd user \"Brian\" should be able to download file \"abc.txt\"\nThis reduces some duplication in feature files. For example, a particular app enabled. @api\n@api\nFeature: add groups\nAs an admin\nI want to be able to add groups\nSo that I can more easily manage access to resources by groups rather than individual users\n@cli\n@cli\nFeature: add group\nAs an admin\nI want to be able to add groups\nSo that I can more easily manage access to resources by groups rather than individual users\n@webUI\n@webUI\nFeature: login users\nAs a user\nI want to be able to log into my account\nSo that I have access to my files\nTagging Scenarios That Require An App\nWhen a feature or scenario requires a core app to be enabled then tag it like:\n@comments-app-required\n@federation-app-required\n@files_trashbin-app-required\n@files_versions-app-required\n@notifications-app-required\n@provisioning-app-required\n@systemtags-app-required\nThe above apps might be disabled on a system-under-test. Those scenarios are run against federated servers running older versions of ownCloud, to ensure that federated sharing can work between different server versions. For example, some user provisioning features may not be relevant when LDAP is the backend for authentication. @local_storage\nthis scenario requires and tests the local storage feature. It helps isolate the browser state. When the browser session is recording, there is a separate video for each scenario. @disablePreviews\ngenerating previews/thumbnails takes time. @issue-32385\nScenario: Change email address\nWhen the user changes the email address to \"new-address@owncloud.com\" using the webUI\n# When the issue is fixed, remove the following step and replace with the commented-out step\nThen the email address \"new-address@owncloud.com\" should not have received an email\n#And the user follows the email change confirmation link received by \"new-address@owncloud.com\" using the webUI\nThen the attributes of user \"Brian\" returned by the API should include\n| email | new-address@owncloud.com |\nThe above scenario is an example of this. For example, after changing a user password we could check that the user can still access some file:\n/**\n* @Then /^as \"([^\"]*)\" (file|folder|entry) \"([^\"]*)\" should exist$/\n*\n* @param string $user\n* @param string $entry\n* @param string $path\n*\n* @return void\n* @throws \\Exception\n*/\npublic function asFileOrFolderShouldExist($user, $entry, $path) {\n$path = $this->substituteInLineCodes($path);\n$this->responseXmlObject = $this->listFolder($user, $path, 0);\nPHPUnit\\Framework\\Assert::assertTrue(\n$this->isEtagValid(),\n\"$entry '$path' expected to exist but not found\"\n);\n}\nIn the above example,\nlistFolder\nis called and does an API call to access the file and then asserts that the response has a valid ETag. For background information on Behaviour-Driven Development (BDD), see\nDan North resources\n. Organizing feature files\nIt may become difficult to maintain or even understand feature files as they grow larger. This is purely for the purpose of documentation."
        },
        {
            "cluster": 4,
            "chunk_content": "Developer Manual\nIntroduction\nGeneral Contributor Guidelines\nCommunity Code of Conduct\nCoding Style & General Guidelines\nDebugging\nPerformance Considerations\nSecurity Guidelines\nBackporting\nHelp and Communication\nDeveloping ownCloud Core\nIntroduction\nSetup Your Development Environment\nApplication Configuration\nTheming\nTranslation\nCode Standards Compliance\nTesting\nownCloud Test Pilots\nDrone Testing\nUnit Testing\nAcceptance Tests\nUser Interface Testing\nAvailable APIs\nThe External API\nThe Provisioning API\nOCS\nThe OCS Notifications API (v1)\nThe OCS REST API\nThe OCS Recipient API\nThe OCS Share API\nThe OCS TOTP Validation API\nThe OCS User Sync API\nNotify Public Link By Email\nThe Roles API\nWebDAV APIs\nThe Comments API\nThe Custom Groups Management API\nThe Files Versions API\nThe Meta API\nThe Search API\nThe Tags API\nThe Trash Bin API\nThe Public Files API\nApplication Development\nFundamental Concepts\nApplication Metadata\nThe Classloader\nConfiguration\nRouting\nControllers\nTemplates\nJavaScript\nCSS\nMiddleware\nDatabase Connectivity\nBackground Jobs\nLogging\nTesting\nThe DI Container\nFilesystem\nRESTful API\nHooks\nPublishing in the ownCloud Marketplace\nChangelog\nMarket App\nAdvanced Concepts\nCustom Filesystem Caches\nCustom Storage Backends\nNotifications\nStorage Backends\nExternal Storage Backends\nTranslation\nTwo-Factor Providers\nUser Management\nCode Signing\nTutorial\nMinimum Requirements\nThe Request Life Cycle\nThe Core Application Files\nRoutes and Controllers\nDatabase Connectivity\nCreate Template Content\nCreate a Navigation Menu\nAdd JavaScript and CSS\nWiring it Up\nApply the Finishing Touches\nAdd a RESTful API\nWriting Tests\nMobile Development\nAndroid\nLibrary Installation\nExamples\niOS\nLibrary Installation\nExamples\nBugtracker\nCode Reviews\nBug Triaging\nFound a Mistake? ownCloud Server\n10.15\nDesktop App\nnext\n5.3\n5.2\nInfinite Scale Documentation\nnext\n7.1\n7.0\nMobile App for Android\nnext\n4.5\n4.4\nMobile App for iOS\nnext\n12.4\n12.3\nownCloud Main Page\nownCloud Server\nnext\n10.15\n10.14\nownCloud Web User Interfaces\nnext\nownCloud Server\nDeveloper Manual\nDeveloping ownCloud Core\nTesting\nAcceptance Tests\nnext\n10.15\n10.14\nEdit this Page\nAcceptance Tests\nTable of Contents\nThe Test Directory Structure\nThe Testing App\nRunning Acceptance Tests\nHow to Write Acceptance Tests\nControlling Running Test Scenarios In Different Environments\nWriting Scenarios For Bugs\nHow to Add New Test Steps\nReferences\nSkipping and Debugging Test Suites in CI\nThe Test Directory Structure\nThis is the structure of the acceptance directory inside\nthe core repository’s\ntests\ndirectory:\ntests\n├── acceptance\n│   ├── config\n│   │   └── behat.yml\n│   ├── features\n│   │   ├── apiTags (example suite of API tests)\n│   │   │   └── feature files (behat gherkin files)\n│   │   ├── bootstrap\n│   │   │   └── Contexts and traits (php files)\n│   │   ├── cliProvisioning (example suite of CLI tests)\n│   │   │   └── feature files (behat gherkin files)\n│   │   ├── lib\n│   │   │   └── Page objects for webUI tests (php files)\n│   │   └── webUILogin (example suite of webUI tests)\n│   │       └── feature files (behat gherkin files)\n│   ├── filesForUpload\n│   └── run.sh\nHere’s a short description of each component of the directory. config/\nThis directory contains\nbehat.yml\nwhich sets up the acceptance tests. In this file we can add new suites and define the contexts needed by each suite. Here’s an example configuration:\ndefault:\nautoload:\n'': '%paths.base%/../features/bootstrap'\nsuites:\napiMain:\npaths:\n- '%paths.base%/../features/apiMain'\ncontexts:\n- FeatureContext: &common_feature_context_params\nbaseUrl:  http://localhost:8080\nadminUsername: admin\nadminPassword: admin\nregularUserPassword: 123456\nocPath: apps/testing/api/v1/occ\n- AppManagementContext:\n- CalDavContext:\n- CardDavContext:\napiCapabilities:\npaths:\n- '%paths.base%/../features/apiCapabilities'\ncontexts:\n- FeatureContext: *common_feature_context_params\n- CapabilitiesContext:\nfeatures/\nThis directory contains sub-directories for each of the test suites. features/suiteName\nThis directory stores\nBehat’s feature files\nfor the test suite. feature/bootstrap\nThis folder contains all the Behat contexts. Contexts contain the PHP code required to run Behat’s scenarios. Running Acceptance Tests\nPreparing to Run Acceptance Tests\nThis is a concise guide to running acceptance tests on ownCloud 10. Before you can do so, you need to meet a few prerequisites available; these are\nownCloud\nComposer\nMySQL\nIn\nphp.ini\non your system, set\nopcache.revalidate_freq=0\nso that changes made to ownCloud\nconfig.php\nby test scenarios are\nimplemented immediately. Now that the prerequisites are satisfied, and assuming that\n$installation_path\nis the location where you cloned the\nownCloud/core\nrepository, the following commands will prepare the installation for running the acceptance tests. # Remove current configuration (if existing)\nsudo rm -rf $installation_path/data/*\nsudo rm -rf $installation_path/config/*\n# Remove existing 'owncloud' database\nmysql -u root -h localhost -e \"drop database owncloud\"\nmysql -u root -h localhost -e \"drop user oc_admin\"\nmysql -u root -h localhost -e \"drop user oc_admin@localhost\"\n# Install ownCloud server with the command-line\nsudo -u www-data ./occ maintenance:install \\\n--database='mysql' --database-name='owncloud' --database-user='root' \\\n--database-pass='mysqlrootpassword' --admin-user='admin' --admin-pass='admin'\nTypes of Acceptance Tests\nThere are 3 types of acceptance tests; API, CLI and webUI. API tests test the ownCloud public APIs. API and CLI tests are run by using the\ntest-acceptance-api\nand\ntest-acceptance-cli\nmake commands. Test Server Environments\nIn order to run acceptance tests, server urls should be specified through environment variables. Environment Variable\nDefault\nDescription\nTEST_SERVER_URL\nhttp://localhost:8080\nOC server url to be used in tests. TEST_SERVER_FED_URL\nhttp://localhost:8180\nOC federated server url to be used in tests. Running Acceptance Tests for a Suite\nRun a command like the following:\nmake test-acceptance-api BEHAT_SUITE=apiTags\nmake test-acceptance-cli BEHAT_SUITE=cliProvisioning\nRunning Acceptance Tests for a Feature\nRun a command like the following:\nmake test-acceptance-api BEHAT_FEATURE=tests/acceptance/features/apiTags/createTags.feature\nmake test-acceptance-cli BEHAT_FEATURE=tests/acceptance/features/cliProvisioning/addUser.feature\nRunning Acceptance Tests for a Tag\nSome test scenarios are tagged. To run test scenarios with a particular tag:\nmake test-acceptance-api BEHAT_SUITE=apiTags BEHAT_FILTER_TAGS=@skip\nmake test-acceptance-cli BEHAT_SUITE=cliProvisioning BEHAT_FILTER_TAGS=@skip\nRunning Acceptance Tests for different User Names and User Attributes\nThe user names and user attributes in test scenarios can be replaced at run-time. The replacement values are defined in\ntests/acceptance/usernames.json\n. For example:\n{\n\"Alice\": {\n\"username\": \"000\",\n\"displayname\": \"0.0\",\n\"email\": \"zero@example.org\",\n\"password\": \"0123\"\n},\n\"Brian\": {\n\"username\": \"1.1\",\n\"displayname\": \"नेपाली name\",\n\"email\": \"nepal@example.org\",\n\"password\": \"नेपाल\"\n},\n\"Carol\": {\n\"username\": \"12E3\",\n\"displayname\": \"12 thousand\",\n\"email\": \"twelve-thousand@example.org\",\n\"password\": \"random12000\"\n},\n\"David\": {\n\"username\": \"123@someone\",\n\"displayname\": \"321@nobody\",\n\"email\": \"someone@example.org\",\n\"password\": \"some123one\"\n},\n\"Emily\": {\n\"username\": \"e+f\",\n\"displayname\": \"a+b-c*d\",\n\"email\": \"emily+fred@example.org\",\n\"password\": \"notsorandom\"\n}\n}\nIf you are running tests locally, define the environment variable\nREPLACE_USERNAMES\nto be true:\nexport REPLACE_USERNAMES=true\nYou can also run the acceptance tests in CI with the replaced user attributes. Commit the changes to\n.drone.star\nand\ntests/acceptance/usernames.json\n, push to GitHub, and make a\ndraft\nPR:\nExample Changes\n'acceptance': {\n'api': {\n'suites': [\n'apiAuth',\n'apiAuthOcs',\n'apiAuthWebDav',\n# and so on...\n],\n'replaceUsernames': True,\n},\n},\nWhen the acceptance tests are run, the user names and attributes will be replaced. Environment Variables\nEnvironment Variable\nDescription\nDIVIDE_INTO_NUM_PARTS\nThe number of parts the test suite will be divided into\nRUN_PART\nThe part-number to test\nExecute the tests by setting the above environment variables and running the usual make command. RUN_PART=1 DIVIDE_INTO_NUM_PARTS=5 make test-acceptance-api\n2. part argument\nIf\nrun.sh\nis used directly to run acceptance tests, the part system can be achieved using the\n--part\nflag. ./run.sh --part 1 5\nWith this method, it is also possible to use environment variables. RUN_PART=1 DIVIDE_INTO_NUM_PARTS=5 ./run.sh\nDisplaying the ownCloud Log\nIt can be useful to see the tail of the ownCloud log when the test run ends. To do that, specify\nSHOW_OC_LOGS=true\n:\nmake test-acceptance-api BEHAT_SUITE=apiTags SHOW_OC_LOGS=true\nStep Through Each Step of a Scenario\nWhen doing test development, or investigating problems with a test or with the system-under-test,\nit is useful to be able to stop the test at each step while investigating what happens. make test-acceptance-api STEP_THROUGH=true BEHAT_FEATURE=tests/acceptance/features/apiComments/createComments.feature:35\n... Environment Variable\nDescription\nDEBUG_ACCEPTANCE_REQUESTS\nOutput the details of each API request. DEBUG_ACCEPTANCE_RESPONSES\nOutput the details of each API response. DEBUG_ACCEPTANCE_API_CALLS\nOutput the details of each API request and response. make test-acceptance-api DEBUG_ACCEPTANCE_API_CALLS=true BEHAT_SUITE=apiTags\nOptional Environment Variables\nIf you define\nSEND_SCENARIO_LINE_REFERENCES\nthen the API tests will send an extra\nX-Request-Id\nheader in each request\nto the API. For example,\napiComments/editComments.feature:26-28\nindicates the apiComments test suite, editComments feature,\nthe scenario at line 26 and the test step at line 28. make test-acceptance-api BEHAT_SUITE=apiTags SEND_SCENARIO_LINE_REFERENCES=true\nIf you want to use an alternative home name using the\nenv\nvariable add to the execution\nOC_TEST_ALT_HOME=1\n, as in the following example:\nmake test-acceptance-api BEHAT_SUITE=apiTags OC_TEST_ALT_HOME=1\nIf you want to have encryption enabled add\nOC_TEST_ENCRYPTION_ENABLED=1\n, as in the following example:\nmake test-acceptance-api BEHAT_SUITE=apiTags OC_TEST_ENCRYPTION_ENABLED=1\nHow to Write Acceptance Tests\nEach acceptance test is a scenario in a feature file in a test suite. Tagging Features By API, CLI and webUI\nTag every feature with its major acceptance test type\napi\n,\ncli\nor\nwebUI\n, as in the following examples. For tests in an app repository, do not tag them with the app name (e.g.,\nfiles_texteditor-app-required\n). Add logic to\ntests/acceptance/run.sh\nwhen you need to add new tags for\nnewer versions. Running tests using release tarballs in CI\nIf you want to run the tests in CI against a system installed from one of the release tarballs, you can use the\ntestAgainstCoreTarball\nsetting in the\nconfig\nsection of\n.drone.star\n. You can use the\ncoreTarball\noption to specify which release tarball to install from. If no tarball version is specified then\ndaily-master-qa\nwill be used. This will only use the release tarballs for running the acceptance tests while the unit and integration tests will run using the git branch. config = {\n'acceptance': {\n'api': {\n'suites': [\n'apiAuth',\n'apiAuthOcs',\n'apiAuthWebDav',\n# and so on...\n],\n'testAgainstCoreTarball': True,\n'coreTarball': '10.7.0',\n},\n},\n}\nWriting Scenarios For Bugs\nIf you are developing a new feature, and the scenarios that you have written do not pass,\nor existing scenarios are failing, then fix the code so that they pass. If the bug is easy to fix, then provide the bugfix and the new acceptance test scenario(s)\nin the same pull request. How to Add New Test Steps\nSee\nthe Behat User Guide\nfor information about writing test step code. Typically this will check a status code returned in the API response. Here’s example code for a\nGiven\nstep:\n/**\n* @Given the administrator has changed the password of user :user to :password\n*\n* @param string $user\n* @param string $password\n*\n* @return void\n* @throws \\Exception\n*/\npublic function adminHasChangedPasswordOfUserTo(\n$user, $password\n) {\n$this->adminChangesPasswordOfUserToUsingTheProvisioningApi(\n$user, $password\n);\n$this->theHTTPStatusCodeShouldBe(\n200,\n\"could not change password of user $user\"\n);\n}\nThe code calls the method for the\nWhen\nstep and then checks the HTTP status code. Here’s example code for a\nWhen\nstep:\n/**\n* @When the administrator changes the password of user :user to :password using the provisioning API\n*\n* @param string $user\n* @param string $password\n*\n* @return void\n* @throws \\Exception\n*/\npublic function adminChangesPasswordOfUserToUsingTheProvisioningApi(\n$user, $password\n) {\n$this->response = UserHelper::editUser(\n$this->getBaseUrl(),\n$user,\n'password',\n$password,\n$this->getAdminUsername(),\n$this->getAdminPassword()\n);\n}\nThe code saves the response so that later\nThen\nsteps can examine it. Here’s example code for a\nThen\nstep:\n/**\n* @Then /^the groups returned by the API should include \"([^\"]*)\"$/\n*\n* @param string $group\n*\n* @return void\n*/\npublic function theGroupsReturnedByTheApiShouldInclude($group) {\n$respondedArray = $this->getArrayOfGroupsResponded($this->response);\nPHPUnit\\Framework\\Assert::assertContains($group, $respondedArray);\n}\nHowever, a\nThen\nstep may need to do actions of its own to retrieve more information about the state of the system. References\nFor more information on Behat, and how to write acceptance tests using it, see\nthe Behat documentation\n. Usage:\n...\n'phpunit': {\n'allDatabases' : {\n'phpVersions': [\n'7.3',\n],\n'skip': True\n},\n}\n...\n'acceptance': {\n'api': {\n'suites': [\n'apiAuth',\n'apiAuthOcs',\n'apiAuthWebDav',\n'apiCapabilities',\n'apiComments'\n],\n'skip': True\n},\n}\n...\nDebug Specific Test Suites\nIn CI, you may want to run only one or specific test suites for debugging purposes. To do so you can use\ndebugSuites\nin the drone config which takes a list of suite names. (Note: remember to set\n'skip': False\nif you are using\nskip\n)\nUsage:\n...\n'acceptance': {\n'api': {\n'suites': [\n'apiAuth',\n'apiAuthOcs',\n'apiAuthWebDav',\n'apiCapabilities',\n'apiComments'\n],\n'debugSuites': ['apiAuth']\n}\n}\n... Usage:\n...\n'acceptance': {\n'apiProxy': {\n'suites': {\n'apiProxySmoketest': 'apiProxySmoke',\n},\n'numberOfParts': 8,\n'skipExceptParts': [3, 7]\n}\n}\n... When ...\nThen ...\n...\nUnit Testing\nUser Interface Testing\nAbout ownCloud\nThe Secure Collaboration Platform\nNews\nPrivacy statement\nImprint\nResources\nFAQ\nHelp\nSecurity\nChangelog\nGet started\nInteract\nRocket.Chat\nForum\nContribute\nCustomer support\n© Copyright 2011-2025, The ownCloud developers."
        },
        {
            "cluster": 0,
            "chunk_content": "These contain Behat’s test cases, called scenarios, which use the Gherkin language. Every suite has to have one or more contexts associated with it. For example, tests that are known to fail and are awaiting fixes are tagged\n@skip\n. This can be useful for finding values that cause problems. Filter tags can also be used to run targeted scenarios after divisions. If you need more scenarios than that, then perhaps there really are multiple features and you should make multiple feature files. Each scenario starts with the\nScenario:\nkeyword followed by a description of the scenario. For example, it could ignore the fact that some\nelement that is usually on the UI is missing, or it can understand that some different UI page will be displayed next. Where it makes the scenario read more easily, use the\nBut\nas well as\nAnd\nkeywords in the\nThen\nsection. This helps real humans to more easily understand scenarios. Scenario Background\nIf all the scenarios in a feature start with a common set of\nGiven\nsteps,\nthen put them into a\nBackground:\nsection. To allow the test runner script to run the features and scenarios relevant to the system-under-test the feature file or individual scenarios are tagged. The test runner script can then filter by tags to select the relevant features or scenarios. For general information on tagging features and scenarios see\nthe Behat tags documentation\n. Tagging the feature or scenario allows all tests for the app to be quickly run or skipped. When writing new test scenarios for a new or changed feature, tag them to be skipped on the previous recent release of ownCloud. Use tag formats like the following to skip on a particular major, minor or patch version. When writing scenarios for new or fixed federated features that are not expected to work with older versions, then skip those scenarios using tags like:\n@skipOnFedOcV10\n@skipOnFedOcV10.4\n@skipOnFedOcV10.5.0\nIf there are significant changes for a new release and many test scenarios have to be modified and skipped on older ownCloud versions\nthen the old scenarios can be left in the feature files for when the test suite is used against an older version of ownCloud. Tag the older scenarios like the following. @notToImplementOnOCIS\nthe scenario is not relevant on an OCIS system. OCIS CI and developers can skip these scenarios. Tags For Tests To Run In Special Environments\nAnnotation\nDescription\n@smokeTest\nthis scenario has been selected as part of a base set of smoke tests. Use this tag on all UI scenarios. If you are writing scenarios to cover features and scenarios that are not currently covered\nby acceptance tests then you may find existing bugs. If the bug is not easy to fix, then:\ncreate an issue describing the bug. write the scenario so that it will fail when the bug is fixed. tag the scenario with the issue number. Now that we have a general background about the scenarios and steps in a feature file, the following things should be kept in mind while writing a feature file:\nAdding comments\nFeature files are themselves a documentation of the feature being tested. It is a good practice to add comments in the code but for feature files, mostly feature & scenario descriptions should be prioritized. However, there are some cases where comments are necessary. An example might be to add a comment to a scenario explaining the step that shows the bug, as well as specifying the replacement after the bug is fixed. Adding tags\nA scenario can have multiple tags. Tags not only help to run a subset of scenarios, but also provide the documentation of the scenario. For example, a scenario tagged with\n@notToImplementOnOcis\ncan be used to track the scenarios that are not to be implemented for the oCIS server. A scenario can also be tagged with a related issue if it describes or refers to a bug. This makes it easier to track bugs and their fixes. For example, a scenario tagged with\n@issue-123\ncan be used to track the scenario that is related to the issue with id\n123\nin the respective repository. The following two factors might complicate the process of assigning/removing tags:\nShould we leave closed issue tags in the scenarios? The same issue may reappear in the future or something similar to it may happen. So, it is better to keep the tags in the scenarios. Which issue to tag in case of multiple issues? - In cases where a scenario pertains to multiple issues, it should be tagged with the most relevant issue. A tagged issue should have a clearer description or more relevant discussion. Inter-scenario spacings\nSince we follow the line numbers of the scenarios in the expected failure files, the scenarios in the feature files should be maintained in a more stable way. This means that the scenarios should not be moved around more often or gaps should be made consistent. One line below the gap is reserved for the tags. There will be two lines of gaps if a scenario has no assigned tags. Usage:\n...\n# inter-scenario gap\n@issue-123                          # reserved tag line\nScenario: Scenario 1\nGiven ... When ...\nThen ...\n# inter-scenario gap\n# reserved tag line\nScenario: Scenario 2\nGiven ..."
        },
        {
            "cluster": 1,
            "chunk_content": "The contexts define the test steps used by the scenarios in the feature files of the test suite. run.sh\nThis script runs the test suites. It is called by the\nmake\ncommands that are used to run acceptance tests. The Testing App\nThe testing app provides an API that allows the acceptance tests to set up the environment of the system-under-test. The testing app must be installed and enabled on the system-under-test. The testing app also provides skeleton folders that the tests can use as the default set of files for new users. CLI tests test the\nocc\ncommand-line commands. webUI tests test the browser-based user interface. webUI tests require an additional environment to be set up. See\nthe UI testing documentation\nfor more information. This allows running the acceptance test suites with different unusual user names, display names,\nemail addresses and passwords. This is useful if you want to\nrun many acceptance tests with an unusual combination of usernames, display names, email addresses and\npasswords without taking up many hours on a local machine. A PR is necessary for testing but is not to be merged\n,\nit is just a way to get test results. When you are finished running the tests, remember to close the PR and leave a comment\ndescribing the outcome of your testing. Running Acceptance Tests Using Part System\nThe part system allows us to divide the test run without knowing how many or which suites are available. Multiple test suites are grouped together in each part. For example, if there are 26 test suites to be grouped into 10 parts then 2 or 3 test suites will be run in each part. The CI can split the test suites into as many pipelines as is appropriate without needing to know the actual names of the test suites. The script below divides the test suite into five parts and runs just the first one. Press enter to resume the test and execute the next test step. This generates a large amount of output, but can be useful to understand exactly what a test is doing and why it fails. A system-under-test could write that string into log entries,\nor report in a way that makes it easier to correlate the test runner API requests with the events in the system-under-test. The rest of a feature file contains the test scenarios. There are 3 types of test steps:\nGiven\nsteps that get the system into the desired state to start the test (e.g., create users and groups, share some files)\nWhen\nsteps that perform the action under test (e.g., upload a file to a share)\nThen\nsteps that verify that the action was successful (e.g., check the HTTP status code, check that other users can access the uploaded file)\nA single scenario should test a single action or logical sequence of actions. The test code is free to achieve the desired system state however it likes. For example, by using an available API, by running a suitable\nocc\ncommand on the system-under-test, or by doing it with the webUI. Typically the test code for\nGiven\nsteps will use an API, because that is usually the most efficient. They specify the action that is being tested. So\nWhen\nsteps should end with a phrase specifying the interface to be tested, such as:\nusing the occ command\nusing the Sharing API\nusing the Provisioning API\nusing the WebDAV API\nusing the webUI\nIf a\nWhen\nstep takes an action that is not expected to succeed, then the step can use the phrase \"tries to\". This helps the test to remain focused on the business\nneed rather than the implementation detail. There are five user names that are typically used in the test scenarios. That helps to be able to automatically replace user names and run all the test scenarios with different unusual user names. The acceptance test code has defaults for the display name and email address of these \"known\" users. Longer tests with a single user read well with the first form. Shorter tests, or sharing tests that mix actions of multiple users, read well with the second form. The user name of the user with administrator privilege on the system-under-test might not be\nadmin\n. Controlling Running Test Scenarios In Different Environments\nA feature or test scenario might only be relevant to run on a system-under-test that has a particular environment. Doing so allows the tests of a particular major type to be quickly run or skipped. It is already a given that the app in the repository is required for running the tests! Tagging Scenarios That Need to Be Skipped\nSkip UI Tests On A Particular Browser\nSome browsers have difficulty with some automated test actions. To skip scenarios for a browser tag them with the relevant tags:\n@skipOnCHROME\n@skipOnFIREFOX\n@skipOnINTERNETEXPLORER\n@skipOnMICROSOFTEDGE\nSkip Tests On A Particular Version Of ownCloud\nThe acceptance test suite is sometimes run against a system-under-test that has an older version of ownCloud. @skipOnOcV10\n@skipOnOcV10.4\n@skipOnOcV10.5.0\nThe acceptance test suite has scenarios that test federated sharing. @skipOnAllVersionsGreaterThanOcV10.8.0\nSkip Tests In Other Environments\nAnnotation\nDescription\n@skipOnDockerContainerTesting\nskip the scenario if the test is running against the ownCloud docker container. Some settings are preset in the docker container and the tests cannot change those, so the related test scenarios must be skipped. @skipOnLDAP\nskip the scenario if the test is running with the LDAP backend. @skipOnStorage:ceph\nskip the scenario if the test is running with\nceph\nbackend storage. @skipOnStorage:scality\nskip the scenario if the test is running with\nscality\nbackend storage. @skipOnEncryption\nskip the scenario if the test is running with encryption enabled. @skipOnEncryptionType:masterkey\nskip the scenario if the test is running with\nmasterkey\nencryption enabled. @skipOnEncryptionType:user-keys\nskip the scenario if the test is running with\nuser-keys\nencryption enabled. @TestAlsoOnExternalUserBackend\nthis scenario is selected as part of a base set of tests to run when a special user backend is in place (e.g., LDAP). @mailhog\nthis scenario requires an email server running\nSpecial Tags for UI Tests\nAnnotation\nDescription\n@insulated\nthis makes the browser driver restart the browser session between each scenario. Use this tag on UI test scenarios that do not need to test thumbnail behavior. Typically use a public API if available, rather than running an\nocc\ncommand via the testing app or entering data in the webUI. Skipping and Debugging Test Suites in CI\nSkip Pipelines\nFor various purposes, you may skip one or more CI pipelines. Use\nskip\nin the drone config to skip the test pipelines. skip\nis available for\njavascript\n,\nphpunit\nand\nacceptance\ntests. If\ndebugSuites\nis included with one or more test suites in it then only those suites will run in CI. Similarly, in the case of test suites that run in parts, you can use\nskipExceptParts\nto specify only which part(s) you want to run."
        },
        {
            "cluster": 3,
            "chunk_content": "Setting\nSTEP_THROUGH=true\nwill cause the test runner to pause after each step. The value sent is a string that indicates the test suite, feature, scenario and line number of the step. Then the steps to execute for that scenario are listed. So the\nGiven\n,\nWhen\nand\nThen\nsteps should come in that order. If there are multiple\nGiven\nor\nWhen\nsteps, then steps after the first start with the keyword\nAnd\n. If there are multiple\nThen\nsteps, then steps after the first start with the keyword\nAnd\nor\nBut\n. Writing a Given Step\nGiven\nsteps are written in the\npresent-perfect tense\n. They specify things that \"have been done\". They can mention the actor that performs the step, when that matters. Writing a When Step\nWhen\nsteps are written in the\nsimple present tense\n. This makes it clear to the reader that the action is not expected to succeed in the normal way. It also allows the test code to act differently when handling the step. Scenario: admin login with invalid password\nGiven the user has browsed to the login page\nWhen the administrator tries to login with an invalid password \"wrongPassword\" using the webUI\n...\nWrite\nWhen\nsteps that state what the user wants to achieve. Sometimes there is a workflow on the UI that takes a few UI actions to achieve the result. Normally write a single\nWhen\nstep. For example, there is a cancel\nbutton available at each step of the workflow. In order to test the cancel button, write smaller\nWhen\nsteps to\ndescribe exactly how the user progresses through the workflow. They should contain the word\nshould\nsomewhere in the step text. Then\nsteps should test an appropriate range of evidence that the\nWhen\naction did happen. Specifying the Actor\nTest steps often need to specify the actor that does the action or check. So that later steps can just mention\nthe user\n. Either form is acceptable. When the actor is the administrator (a special user with privileges) then use\nthe administrator\nin the step text. This makes it clearer to understand which entity is required in which position of the sentence. write a scenario that demonstrates the existing wrong behavior. include commented-out steps in the scenario to document what is the expected correct behavior. When the bug is fixed then the step about\nshould not have received an email\nwill fail. CI will fail, and so the developer will notice this scenario and will have to correct it. In addition to that, follow these guidelines. Given Steps\nThe code of a\nGiven\nstep should achieve the desired system state by whatever means is quick to execute. If there is a simple way to gain confidence that the\nGiven\nstep was successful, then do it. Doing simple confidence checks in\nGiven\nsteps makes it easier to catch some unexpected problem during the scenario\nGiven\nsection. When Steps\nThe code of a\nWhen\nstep should perform the action but not check its result. A\nWhen\nstep should not ordinarily fail. Often a\nWhen\nstep will save the response. It is the responsibility of later\nThen\nsteps to decide if the scenario passed or failed. Then Steps\nThe code of a\nThen\nstep should check some result of the\nWhen\naction. Often it will find information in the saved response and assert something. - Yes, we should. For this, the following things should be kept in mind:\nBetween two scenarios, one blank line should be left."
        }
    ]
}