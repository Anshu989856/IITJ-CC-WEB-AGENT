{
    "file_name": "ocis_7.0_availability_scaling_availability_scaling.html",
    "file_path": "./owncloud_docs\\ocis_7.0_availability_scaling_availability_scaling.html",
    "chunks": [
        {
            "cluster": 3,
            "chunk_content": "Documentation for ownCloud (A Kiteworks Company)\nInfinite Scale Documentation\nIntroduction\nQuick Guide\nInfinite Scale Overview\nArchitecture and Concepts\nAvailability and Scalability\nSecurity Aspects\nDeployment\nPrerequisites\nStorage\nGeneral Storage Considerations\nNetwork File System\nS3\nPosixFS\nGeneral Information\nThe ocis init Command\nContainer Orchestration\nOffice Applications using WOPI\nSecuring oCIS\nUser Triggered GDPR Report\nServices\nGeneral Information\nDeployment Considerations\nEnvironment Variable Notes\nEnvironment Variables with Special Scope\nEnvironment Variable Changes\nRegistry\nCaching and Persistence\nGateways\nLogging\nPorts Used\nTransport Layer Security\nList of Services\nActivitylog\nAntivirus\nApp Provider\nApp Registry\nAudit\nAuth App\nAuth Basic\nAuth Bearer\nAuth Machine\nAuth Service\nClientlog\nCollaboration\nEventhistory\nFrontend\nGateway\nGraph\nGroups\nIDM\nInvitations\nIDP\nNATS\nNotifications\nOCDAV\nOCM\nOCS\nPolicies\nPostprocessing\nProxy\nSearch\nSettings\nSharing\nSSE\nStore\nStorage-Publiclink\nStorage-Shares\nStorage-System\nStorage-Users\nThumbnails\nUserlog\nUsers\nWeb\nWebDAV\nWebfinger\nWeb UI\nCustom Configuration\nCustom Theming\nMaintenance\nBackup and Restore\nBackup Considerations\nBackup\nRestore\nMaintenance Commands\nListing Space IDs\nListing User IDs\nMigration and Upgrades\nUpgrading Infinite Scale\nMonitoring\nPrometheus\nConfiguration Examples\nOffice Integration\nSearch\nDeployment Examples\nMinimal Bare Metal\nBare Metal with systemd\nContainer Setup\nUbuntu with Docker Compose\nLocal Production Setup\nDeployment on Hetzner\nSetup Federations\nScienceMesh Setup\nAdditional Information\nKnowledge Base\nInfinite Scale Documentation\n7.0\nDesktop App\nnext\n5.3\n5.2\nInfinite Scale Documentation\nnext\n7.1\n7.0\nMobile App for Android\nnext\n4.5\n4.4\nMobile App for iOS\nnext\n12.4\n12.3\nownCloud Main Page\nownCloud Server\nnext\n10.15\n10.14\nownCloud Web User Interfaces\nnext\nInfinite Scale Documentation\nInfinite Scale Overview\nAvailability and Scalability\nnext\n7.1\n7.0\nEdit this Page\nAvailability and Scalability\nTable of Contents\nIntroduction\nTerminology\nSupporting Questions\nAvailability\nSingle Server Setup\nForms of High Availability\nScalability\nContainer\nDeployment Evolution\nIntroduction\nThere are many ways to achieve availability and scalability, but certain aspects depend on each other and decisions have to be considered carefully to optimize the outcome. Virtualized Linux operating systems in Docker containers. Summary\nWhile such a setup may suffice for small environments or testing purposes, the efforts for protection, maintenance, backup and restore or migration to a more powerful environment, etc., must be carefully evaluated before starting production. Separating User Data\nThe first consideration in terms of availability, flexibility and scalability should be where to store user data. It is\nhighly recommended\nto physically separate user data from the Infinite Scale instance and store them on a shared filesystem. See the\nFilesystems and Shared Storage\nsection for supported types. Separating the compute from the storage part may sound contrary with respect to the report about availability referenced above. Summary\nSuch a setup is also recommended for smaller environments or testing purposes. Summary\nAs there are many ways to implement a required scenario, ownCloud support\ncannot\ngive advice for a particular solution that fits your needs but may be able to help you get the required Infinite Scale component ready to run. For availability, storing user files is by nature mandatory to be on\nshared storage\nto be accessible by the nodes and/or services. Container\nUsing a container to encapsulate a service can dramatically ease migration or multiplication of services, which also has an effect on availability. This is because a container is a standard unit of software that packages code and all its dependencies, so the application runs fast and reliably and can easily be moved from one computing environment to another. Summary\nContainers are independent of the underlying infrastructure. Containers are portable across clouds and OS distributions\n. Deployment Evolution\nKubernetes\nis software managing a cluster of Linux containers as a\nsingle system\nwhich is a further evolution in achieving the goal of availability and scalability. Summary\nThinking about Infinite Scale as a system providing microservices by design which is also delivered as container, you can\nabstract with Kubernetes the underlying infrastructure and focus on the services to be deployed when necessary, where necessary, with the degree of automation as required\n. Architecture and Concepts\nSecurity Aspects\nAbout ownCloud\nThe Secure Collaboration Platform\nNews\nPrivacy statement\nImprint\nResources\nFAQ\nHelp\nSecurity\nChangelog\nGet started\nInteract\nRocket.Chat\nForum\nContribute\nCustomer support\n© Copyright 2011-2025, The ownCloud developers."
        },
        {
            "cluster": 2,
            "chunk_content": "This guide gives a brief overview about running a modern, microservices-based software like Infinite Scale as a single or distributed instance. Because Infinite Scale is by design enabled to run as a distributed service and not a static monolithic service block, you can achieve availability\nand\nscalability with well-made decisions. Scalability\nScalability means adding more instances. Horizontal scalability, which is also known as\nscale-out\n, can be performed by adding more hardware resources like physical or virtual servers. Vertical Scalability, also known as\nscale-up\n, can be performed by getting more powerful hardware that can either outperform the replaced one and/or run more services. What is the level of complexity coming along with the measures taken like implementation, maintenance, ability to adapt to dynamic requirements, etc.? This changes when you take a services-centered view. While a service may be up and running, it might not respond accordingly to requests because of scaling factors. But it usually does not or only partially solves the scalability issues. In Gartner’s report\nHow Systems Complexity Reduces Uptime\n(pdf copy)\nfrom 2021, you can see that the more components you have the lower the resulting availability will be, which is especially true when using a bunch of monolithic software components. — © Gartner\nHow Systems Complexity Reduces Uptime\nIn this quote, three-nines refers to 99.9%, while two-nines means 99%. Single Server Setup\nIf you have Infinite Scale running on the same physical or virtual server where its configuration and the user data is located, a hard- or software failure of any component might require much bigger efforts to bring back the instance to production. Unavailability and/or data loss is more likely to occur. As with any single server environment:\nScalability is limited to vertical scalability\n. This is because compute environments are more dynamic and storage environments are more static. In case of a failure, it is much easier to fix the defect because of separated components. Scalability is still limited to vertical scalability\n. Scalability is hardware dependent and in case of an active-passive setup, you can even get reduced scalability\n. Scalability is much better but lacks when it comes to load-based dynamic assignment of services\n. Scalability\nThere are two classic ways to achieve scalability, which is scale-up and scale-out. The pictures below show the different ways of classic scaling\nWhat may sound simple with regard to a\nservice\n, services can be a complex topic in reality as they may contain a lot of software components and their configuration building it. Adding more services or migrating a service can therefore be a challenging task adding complexity and can introduce sources of error. Summary\nScalability and availability are often aligned to each other and the decision how to achieve the goal set can be a complex task. This becomes even more true when dynamic load balancing comes into play. Because services consist of many components to take care of, real dynamic adaption and dynamic migration may be hard to achieve\n."
        },
        {
            "cluster": 0,
            "chunk_content": "Due to this design, decisions made can always be revised and adapted to new requirements. Supporting Questions\nThe following questions may help in the decision:\nWhat is the goal? What measures are needed to achieve this protection? How do you want to scale? Will the measures taken result in the goal you have set? This questionnaire is not static and more rounds may be needed to refine each item. With every round the result will become better and clearer. Tasks and actions can be taken and responsibilities can be defined."
        },
        {
            "cluster": 1,
            "chunk_content": "Terminology\nHigh availability\nHigh availability is a method that groups servers that support applications or services that can be reliably used with a minimum amount of downtime. Availability\nTraditionally, availability concepts often focus on monolithic hardware and software components. This means for clients, the driver for the measures taken is not just \"available\". The availability of a system with ten components, each having three-nines availability, is reduced to two-nines, increasing potential system downtime from 44 minutes per month to 7 hours 18 minutes per month. Storage systems contribute with a static high availability number to the overall systems availability. Forms of High Availability\nHigh Availability with its flavors active-active / active-passive layout or clustering provides redundancy by eliminating the node as a single point of failure. Multiple nodes are able to provide availability in these scenarios:\nSoftware crashes, either due to operating system failure or unrecoverable applications. Logically or physically severed network if the fail-over appliance is on a separate network not impacted by the failure. Regular planned node maintenance. Classic High Availability\nWhen using the classic form of high availability (HA), you can either create a setup where the nodes are both active (active-active) or one node only serves as a fallback, waiting for a failure to occur (active-passive). With an A-A setup, a load balancer is needed in front of the nodes. In case of a failure, the remaining node has to be capable of taking over all the load they shared before the other node failed. Summary\nThis use case can be considered if hardware availability is the primary objective. When using an active-active configuration, each node is addressed by a load balancer for load distribution. This requires that the nodes have the same setup and services are bound to the nodes. Clustering\nThe main objective for clustering is not only availability but also distributing load across\nmultiple\nnodes. With clustering a load balancer (LB) is mandatory. Summary\nClustering provides better availability and scalability for growing loads and covers fail-over if a node fails but it still focuses only on hardware. A cluster environment can grow very complex with many dependencies, see the section\nAvailability\n."
        },
        {
            "cluster": 4,
            "chunk_content": "Virtualization\nVirtualization is the ability to abstract hardware, software or a deployment. Virtualized hardware like VMWare, KVM, HyperV, VirtualBox etc. Virtualization of a deployment, e.g. What do you want to protect against? What are the costs for implementation and runtime? Using a sophisticated hardware setup can be one way to solve this. Hardware failures, including storage hardware, CPU, RAM, network interfaces, etc. Virtualization host system failures, including unplanned and scheduled maintenance."
        }
    ]
}